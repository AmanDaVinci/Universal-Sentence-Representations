{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Representations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import SNLI\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up fields\n",
    "TEXT = torchtext.data.Field(lower=True, batch_first=True, tokenize=\"spacy\", include_lengths=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, unk_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data= SNLI.splits(text_field=TEXT, label_field=LABEL, root=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, vectors=GloVe(cache=data_path))\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x28]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x15]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([32, 28]), torch.Size([32]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.premise), batch.premise[0].shape, batch.premise[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   2,  475, 8667, 1146,   18,   21, 1766,    3,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1]), tensor(8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.premise[0][0], batch.premise[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a father lovingly stares at his newborn . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([TEXT.vocab.itos[i] for i in batch.premise[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a mother looks at her baby . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([TEXT.vocab.itos[i] for i in batch.hypothesis[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos[batch.label[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'entailment': 0, 'contradiction': 1, 'neutral': 2})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[batch.premise[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 17, 300])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[batch.hypothesis[0]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels=[]\n",
    "for batch in train_iter:\n",
    "    labels.append(batch.label)\n",
    "labels = torch.cat(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count = Counter(labels.tolist())\n",
    "labels_count.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 300]), torch.Size([32, 300]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise_emb = TEXT.vocab.vectors[batch.premise[0]]\n",
    "premise_agg = torch.mean(premise_emb, dim=1)\n",
    "hypothesis_emb = TEXT.vocab.vectors[batch.hypothesis[0]]\n",
    "hypothesis_agg = torch.mean(hypothesis_emb, dim=1)\n",
    "premise_agg.shape, hypothesis_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 300]), torch.Size([32, 300]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = premise_agg - hypothesis_agg\n",
    "prod = premise_agg * hypothesis_agg\n",
    "diff.shape, prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat((premise_agg, hypothesis_agg, diff, prod), dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineWordEmb(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        return torch.mean(sentence_embed, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Unidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks without packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x30]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x17]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 26\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "num_directions = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 300])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed = TEXT.vocab.vectors[batch.premise[0]]\n",
    "sent_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(batch_size, seq_len, input_size)\n",
    "h0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)\n",
    "c0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(sent_embed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30, 100]), torch.Size([1, 32, 100]), torch.Size([1, 32, 100]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hn.shape, cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden = hn.squeeze()\n",
    "sent_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks with packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32, 32, 32, 32, 32, 32, 32, 31, 29, 26, 24, 21, 18, 16, 14, 12, 11,  8,\n",
       "         6,  4,  3,  3,  2,  2,  2,  2,  2,  2,  1,  1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(sent_embed, lengths=batch.premise[1], batch_first=True, enforce_sorted=False)\n",
    "x_packed.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x_packed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden = hn.squeeze()\n",
    "sent_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidirectional LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, batch_size, hidden_size=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(input_size=embeddings.shape[-1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        x_packed = pack_padded_sequence(sentence_embed, lengths=sentence[1], batch_first=True, enforce_sorted=False)\n",
    "        _, (sent_hidden, _) = lstm(x_packed, (self.h0, self.c0))\n",
    "        return sent_hidden.squeeze() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x30]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x17]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 26\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "num_directions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 300])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed = TEXT.vocab.vectors[batch.premise[0]]\n",
    "sent_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(batch_size, seq_len, input_size)\n",
    "h0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)\n",
    "c0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32, 32, 32, 32, 32, 32, 32, 31, 29, 26, 24, 21, 18, 16, 14, 12, 11,  8,\n",
       "         6,  4,  3,  3,  2,  2,  2,  2,  2,  2,  1,  1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(sent_embed, lengths=batch.premise[1], batch_first=True, enforce_sorted=False)\n",
    "x_packed.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x_packed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]), torch.Size([32, 100]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_forward = hn[0]\n",
    "hn_backward = hn[1]\n",
    "hn_forward.shape, hn_backward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_bi = torch.cat((hn_forward, hn_backward), dim=1)\n",
    "sent_bi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, batch_size, hidden_size=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(bidirectional=True, input_size=embeddings.shape[-1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.h0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        x_packed = pack_padded_sequence(sentence_embed, lengths=sentence[1], batch_first=True, enforce_sorted=False)\n",
    "        _, (sent_hidden, _) = lstm(x_packed, (self.h0, self.c0))\n",
    "        sent_bi = torch.cat((sent_hidden[0], sent_hidden[1]), dim=1)\n",
    "        return sent_bi.squeeze() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Bidirectional LSTM with Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x28]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x15]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 26\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "num_directions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 28, 300])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed = TEXT.vocab.vectors[batch.premise[0]]\n",
    "sent_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(batch_size, seq_len, input_size)\n",
    "h0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)\n",
    "c0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32, 32, 32, 32, 32, 32, 30, 30, 27, 24, 20, 16, 14, 11,  7,  7,  5,  5,\n",
       "         5,  2,  2,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(sent_embed, lengths=batch.premise[1], batch_first=True, enforce_sorted=False)\n",
    "x_packed.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x_packed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, seq_len = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 28, 200])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[output == 0] = -1e9\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden_pooled, _ = torch.max(output, dim=1)\n",
    "sent_hidden_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 10, 19, 14, 12, 28, 14, 21,  6,  8,  9, 10, 16, 11, 19, 11,  6, 12,\n",
       "        14, 19, 11, 10, 11, 13, 14, 13, 16, 13,  8,  9, 10,  9])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fb58f4e11d0>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x161.28 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(output[2].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1052,  0.0977,  0.0547,  0.0662,  0.0568,  0.1824,  0.1934,  0.1079,\n",
       "         0.0025,  0.0611, -0.0229, -0.0013,  0.0222, -0.0498,  0.0785,  0.1041,\n",
       "         0.0950,  0.1710,  0.1716,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         0.0000,  0.0000,  0.0000,  0.0000], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[2, :, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Encoder with Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPool(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, batch_size, hidden_size=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(bidirectional=True, input_size=embeddings.shape[-1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.h0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        x_packed = pack_padded_sequence(sentence_embed, lengths=sentence[1], batch_first=True, enforce_sorted=False)\n",
    "        output, (sent_hidden, _) = lstm(x_packed, (self.h0, self.c0))\n",
    "        output, seq_len = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        sent_hidden_pooled, _ = torch.max(output, dim=1)\n",
    "        return sent_hidden_pooled "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, encoded_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4 * encoded_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, premise, hypothesis):\n",
    "        u = self.encoder(premise)\n",
    "        v = self.encoder(hypothesis)\n",
    "        diff = u - v\n",
    "        prod = u * v\n",
    "        x = torch.cat((u, v, diff, prod), dim=1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaselineWordEmb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-b32ee208fa78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoded_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaselineWordEmb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaselineWordEmb' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_dim = TEXT.vocab.vectors.shape[-1]\n",
    "encoder = BaselineWordEmb(embeddings=TEXT.vocab.vectors)\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 100\n",
    "encoder = UniLSTM(embeddings=TEXT.vocab.vectors, batch_size=BATCH_SIZE, hidden_size=encoded_dim)\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 200\n",
    "encoder = BiLSTM(embeddings=TEXT.vocab.vectors, batch_size=BATCH_SIZE, hidden_size=int(encoded_dim/2))\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 200\n",
    "encoder = BiLSTMPool(embeddings=TEXT.vocab.vectors, batch_size=BATCH_SIZE, hidden_size=int(encoded_dim/2))\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): BiLSTMPool(\n",
       "    (emb): Embedding(33672, 300)\n",
       "    (lstm): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0934, grad_fn=<NllLossBackward>),\n",
       " torch.Size([32, 3]),\n",
       " tensor([1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 2, 2, 0, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(batch.premise, batch.hypothesis)\n",
    "loss = criterion(pred, batch.label)\n",
    "loss, pred.shape, batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch#0 Loss: 1.093\n",
      "Epoch#100 Loss: 0.000\n",
      "Epoch#200 Loss: 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-7321aa3fab15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iters = 1000\n",
    "print_freq = 100\n",
    "for idx in range(iters):\n",
    "    pred = model(batch.premise, batch.hypothesis)\n",
    "    loss = criterion(pred, batch.label)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    if idx % print_freq == 0:\n",
    "        print(f\"Epoch#{idx} Loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 2, 2, 0, 2, 2, 2, 2]),\n",
       " tensor([1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 2, 2, 0, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(batch.premise, batch.hypothesis)\n",
    "torch.argmax(pred, dim=1), batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): UniLSTM(\n",
       "    (emb): Embedding(33672, 300)\n",
       "    (lstm): LSTM(300, 100, bias=32)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch#0 Step#0 Loss: 2.033\n",
      "Epoch#0 Step#100 Loss: 0.995\n",
      "Epoch#0 Step#200 Loss: 1.178\n",
      "Epoch#0 Step#300 Loss: 0.932\n",
      "Epoch#0 Step#400 Loss: 0.861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-cd54847973a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-581f3f05d874>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, premise, hypothesis)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-64b7b8d8fd1e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msentence_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx_packed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_packed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msent_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_packed\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n\u001b[0;32m--> 525\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "print_freq = 100\n",
    "for epoch in range(epochs):\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        pred = model(batch.premise, batch.hypothesis)\n",
    "        loss = criterion(pred, batch.label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if idx % print_freq == 0:\n",
    "            print(f\"Epoch#{epoch} Step#{idx} Loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch = next(iter(val_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'entailment': 0, 'contradiction': 1, 'neutral': 2})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(val_batch.premise, val_batch.hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, truth):\n",
    "    correct = (torch.argmax(pred, dim=1) == truth).sum()\n",
    "    return (correct.float() / val_batch.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7188)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred, val_batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5372)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for batch in val_iter:\n",
    "    with torch.no_grad():\n",
    "        pred = model(batch.premise, batch.hypothesis)\n",
    "    accuracies.append(accuracy(pred, batch.label))\n",
    "    #print(\" \".join([TEXT.vocab.itos[i] for i in batch.premise[0]]))\n",
    "    #print(\" \".join([TEXT.vocab.itos[i] for i in batch.hypothesis[0]]))\n",
    "    #print(torch.argmax(pred, dim=1), batch.label)\n",
    "    #print()\n",
    "torch.tensor(accuracies).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prod] *",
   "language": "python",
   "name": "conda-env-prod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

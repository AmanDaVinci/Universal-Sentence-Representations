{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Universal Sentence Representations\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import SNLI\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up fields\n",
    "TEXT = torchtext.data.Field(lower=True, batch_first=True, tokenize=\"spacy\", include_lengths=True)\n",
    "LABEL = torchtext.data.Field(sequential=False, unk_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data= SNLI.splits(text_field=TEXT, label_field=LABEL, root=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, vectors=GloVe(cache=data_path))\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train_data, val_data, test_data), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x26]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x19]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, torch.Size([32, 26]), torch.Size([32]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.premise), batch.premise[0].shape, batch.premise[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([143,  15, 168,   8,   2, 150, 113, 656,   3,   1,   1,   1,   1,   1,\n",
       "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1]),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.premise[0][0], batch.premise[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "several people sit on a bench watching traffic . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([TEXT.vocab.itos[i] for i in batch.premise[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "several people sitting at the dinner table . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join([TEXT.vocab.itos[i] for i in batch.hypothesis[0][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.itos[batch.label[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'entailment': 0, 'contradiction': 1, 'neutral': 2})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 300])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[batch.premise[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 17, 300])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors[batch.hypothesis[0]].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "labels=[]\n",
    "for batch in train_iter:\n",
    "    labels.append(batch.label)\n",
    "labels = torch.cat(labels)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_count = Counter(labels.tolist())\n",
    "labels_count.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 300]), torch.Size([32, 300]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "premise_emb = TEXT.vocab.vectors[batch.premise[0]]\n",
    "premise_agg = torch.mean(premise_emb, dim=1)\n",
    "hypothesis_emb = TEXT.vocab.vectors[batch.hypothesis[0]]\n",
    "hypothesis_agg = torch.mean(hypothesis_emb, dim=1)\n",
    "premise_agg.shape, hypothesis_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 300]), torch.Size([32, 300]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = premise_agg - hypothesis_agg\n",
    "prod = premise_agg * hypothesis_agg\n",
    "diff.shape, prod.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1200])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat((premise_agg, hypothesis_agg, diff, prod), dim=1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineWordEmb(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        return torch.mean(sentence_embed, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Unidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks without packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x30]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x17]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 26\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "num_directions = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 300])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed = TEXT.vocab.vectors[batch.premise[0]]\n",
    "sent_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(batch_size, seq_len, input_size)\n",
    "h0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)\n",
    "c0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(sent_embed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30, 100]), torch.Size([1, 32, 100]), torch.Size([1, 32, 100]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, hn.shape, cn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden = hn.squeeze()\n",
    "sent_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks with packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32, 32, 32, 32, 32, 32, 32, 31, 29, 26, 24, 21, 18, 16, 14, 12, 11,  8,\n",
       "         6,  4,  3,  3,  2,  2,  2,  2,  2,  2,  1,  1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(sent_embed, lengths=batch.premise[1], batch_first=True, enforce_sorted=False)\n",
    "x_packed.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x_packed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden = hn.squeeze()\n",
    "sent_hidden.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidirectional LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, batch_size, hidden_size=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(input_size=embeddings.shape[-1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.h0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(num_layers, batch_size, hidden_size)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        x_packed = pack_padded_sequence(sentence_embed, lengths=sentence[1], batch_first=True, enforce_sorted=False)\n",
    "        _, (sent_hidden, _) = lstm(x_packed, (self.h0, self.c0))\n",
    "        return sent_hidden.squeeze() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x30]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x17]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 26\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "num_directions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30, 300])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed = TEXT.vocab.vectors[batch.premise[0]]\n",
    "sent_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(batch_size, seq_len, input_size)\n",
    "h0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)\n",
    "c0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32, 32, 32, 32, 32, 32, 32, 31, 29, 26, 24, 21, 18, 16, 14, 12, 11,  8,\n",
       "         6,  4,  3,  3,  2,  2,  2,  2,  2,  2,  1,  1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(sent_embed, lengths=batch.premise[1], batch_first=True, enforce_sorted=False)\n",
    "x_packed.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x_packed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 100]), torch.Size([32, 100]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hn_forward = hn[0]\n",
    "hn_backward = hn[1]\n",
    "hn_forward.shape, hn_backward.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_bi = torch.cat((hn_forward, hn_backward), dim=1)\n",
    "sent_bi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, batch_size, hidden_size=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(bidirectional=True, input_size=embeddings.shape[-1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.h0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        x_packed = pack_padded_sequence(sentence_embed, lengths=sentence[1], batch_first=True, enforce_sorted=False)\n",
    "        _, (sent_hidden, _) = lstm(x_packed, (self.h0, self.c0))\n",
    "        sent_bi = torch.cat((sent_hidden[0], sent_hidden[1]), dim=1)\n",
    "        return sent_bi.squeeze() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder: Bidirectional LSTM with Max Pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
       "\t[.premise]:('[torch.LongTensor of size 32x26]', '[torch.LongTensor of size 32]')\n",
       "\t[.hypothesis]:('[torch.LongTensor of size 32x19]', '[torch.LongTensor of size 32]')\n",
       "\t[.label]:[torch.LongTensor of size 32]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "seq_len = 26\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_layers = 1\n",
    "num_directions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 26, 300])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_embed = TEXT.vocab.vectors[batch.premise[0]]\n",
    "sent_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = torch.randn(batch_size, seq_len, input_size)\n",
    "h0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)\n",
    "c0 = torch.randn(num_layers*num_directions, batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([32, 32, 32, 32, 32, 32, 31, 28, 25, 23, 20, 15, 12, 11, 10,  9,  7,  7,\n",
       "         5,  5,  3,  2,  2,  2,  1,  1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(sent_embed, lengths=batch.premise[1], batch_first=True, enforce_sorted=False)\n",
    "x_packed.batch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hn, cn) = lstm(x_packed, (h0,c0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, seq_len = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 26, 200])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[output == 0] = -1e9\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden_pooled,sent_hidden_idx = torch.max(output, dim=1)\n",
    "sent_hidden_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 16,  8, 14,  8, 11, 10, 12, 11, 15, 13, 11,  6,  7, 24, 21,  7, 20,\n",
       "        18, 10, 26, 11, 12,  7, 20, 16,  9, 11, 12, 10,  8, 18])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fc08d0f1550>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x144 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(output[2, :5].detach().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.5015e-02,  3.3774e-01,  3.4187e-01,  2.7755e-01,  3.7114e-01,\n",
       "         2.6275e-01,  2.2479e-01,  1.6546e-01, -1.0000e+04, -1.0000e+04,\n",
       "        -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
       "        -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
       "        -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04, -1.0000e+04,\n",
       "        -1.0000e+04], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[2, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 200])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_hidden_idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM Encoder with Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMPool(nn.Module):\n",
    "    \n",
    "    def __init__(self, embeddings, batch_size, hidden_size=100, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding.from_pretrained(embeddings, freeze=False)\n",
    "        self.lstm = nn.LSTM(bidirectional=True, input_size=embeddings.shape[-1], hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.h0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "        self.c0 = torch.randn(num_layers*2, batch_size, hidden_size)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        sentence_embed = self.emb(sentence[0])\n",
    "        x_packed = pack_padded_sequence(sentence_embed, lengths=sentence[1], batch_first=True, enforce_sorted=False)\n",
    "        output, (sent_hidden, _) = lstm(x_packed, (self.h0, self.c0))\n",
    "        output, seq_len = torch.nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        sent_hidden_pooled, _ = torch.max(output, dim=1)\n",
    "        return sent_hidden_pooled "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, encoded_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(4 * encoded_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "    \n",
    "    def forward(self, premise, hypothesis):\n",
    "        u = self.encoder(premise)\n",
    "        v = self.encoder(hypothesis)\n",
    "        diff = u - v\n",
    "        prod = u * v\n",
    "        x = torch.cat((u, v, diff, prod), dim=1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaselineWordEmb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-b32ee208fa78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mencoded_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaselineWordEmb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaselineWordEmb' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_dim = TEXT.vocab.vectors.shape[-1]\n",
    "encoder = BaselineWordEmb(embeddings=TEXT.vocab.vectors)\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 100\n",
    "encoder = UniLSTM(embeddings=TEXT.vocab.vectors, batch_size=BATCH_SIZE, hidden_size=encoded_dim)\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 200\n",
    "encoder = BiLSTM(embeddings=TEXT.vocab.vectors, batch_size=BATCH_SIZE, hidden_size=int(encoded_dim/2))\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dim = 200\n",
    "encoder = BiLSTMPool(embeddings=TEXT.vocab.vectors, batch_size=BATCH_SIZE, hidden_size=int(encoded_dim/2))\n",
    "model = Classifier(encoder, encoded_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): BiLSTMPool(\n",
       "    (emb): Embedding(33672, 300)\n",
       "    (lstm): LSTM(300, 100, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.0934, grad_fn=<NllLossBackward>),\n",
       " torch.Size([32, 3]),\n",
       " tensor([1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 2, 2, 0, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(batch.premise, batch.hypothesis)\n",
    "loss = criterion(pred, batch.label)\n",
    "loss, pred.shape, batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch#0 Loss: 1.093\n",
      "Epoch#100 Loss: 0.000\n",
      "Epoch#200 Loss: 0.000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-7321aa3fab15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iters = 1000\n",
    "print_freq = 100\n",
    "for idx in range(iters):\n",
    "    pred = model(batch.premise, batch.hypothesis)\n",
    "    loss = criterion(pred, batch.label)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    opt.zero_grad()\n",
    "    if idx % print_freq == 0:\n",
    "        print(f\"Epoch#{idx} Loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 2, 2, 0, 2, 2, 2, 2]),\n",
       " tensor([1, 2, 2, 2, 1, 2, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 1, 0, 1, 1, 2, 2, 1, 0,\n",
       "         1, 2, 2, 0, 2, 2, 2, 2]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(batch.premise, batch.hypothesis)\n",
    "torch.argmax(pred, dim=1), batch.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): UniLSTM(\n",
       "    (emb): Embedding(33672, 300)\n",
       "    (lstm): LSTM(300, 100, bias=32)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch#0 Step#0 Loss: 2.033\n",
      "Epoch#0 Step#100 Loss: 0.995\n",
      "Epoch#0 Step#200 Loss: 1.178\n",
      "Epoch#0 Step#300 Loss: 0.932\n",
      "Epoch#0 Step#400 Loss: 0.861\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-cd54847973a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-81-581f3f05d874>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, premise, hypothesis)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpremise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-64b7b8d8fd1e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msentence_embed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx_packed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_embed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_packed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msent_hidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_packed\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mmax_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/prod/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n\u001b[0;32m--> 525\u001b[0;31m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "print_freq = 100\n",
    "for epoch in range(epochs):\n",
    "    for idx, batch in enumerate(train_iter):\n",
    "        pred = model(batch.premise, batch.hypothesis)\n",
    "        loss = criterion(pred, batch.label)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        if idx % print_freq == 0:\n",
    "            print(f\"Epoch#{epoch} Step#{idx} Loss: {loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch = next(iter(val_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {'entailment': 0, 'contradiction': 1, 'neutral': 2})"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(val_batch.premise, val_batch.hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, truth):\n",
    "    correct = (torch.argmax(pred, dim=1) == truth).sum()\n",
    "    return (correct.float() / val_batch.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7188)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pred, val_batch.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5372)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies = []\n",
    "for batch in val_iter:\n",
    "    with torch.no_grad():\n",
    "        pred = model(batch.premise, batch.hypothesis)\n",
    "    accuracies.append(accuracy(pred, batch.label))\n",
    "    #print(\" \".join([TEXT.vocab.itos[i] for i in batch.premise[0]]))\n",
    "    #print(\" \".join([TEXT.vocab.itos[i] for i in batch.hypothesis[0]]))\n",
    "    #print(torch.argmax(pred, dim=1), batch.label)\n",
    "    #print()\n",
    "torch.tensor(accuracies).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prod] *",
   "language": "python",
   "name": "conda-env-prod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_SENTEVAL = 'SentEval'\n",
    "PATH_TO_DATA = 'SentEval/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import logging\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer import Trainer\n",
    "from models.embedding_encoder import EmbeddingEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, PATH_TO_SENTEVAL)\n",
    "import senteval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Embedding Average Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_name': 'baseline',\n",
       " 'epochs': 20,\n",
       " 'encoder': 'EmbeddingEncoder',\n",
       " 'batch_size': 128,\n",
       " 'learning_rate': 0.001,\n",
       " 'seed': 42,\n",
       " 'debug': False,\n",
       " 'device': 'cpu',\n",
       " 'num_workers': 4,\n",
       " 'valid_freq': 1000,\n",
       " 'save_freq': 2000,\n",
       " 'test_checkpoint': 'best-model.pt'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configs.baseline import config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer:--------------------------------------------------\n",
      "INFO:trainer:EXPERIMENT: baseline\n",
      "INFO:trainer:--------------------------------------------------\n",
      "INFO:trainer:Setting seed: 42\n",
      "INFO:trainer:Loading data ...\n",
      "INFO:trainer:Using device: cpu\n",
      "INFO:trainer:Loading checkpoint from checkpoints/baseline/best-model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]\tAccuracy: 0.777 Total Loss: 1.528\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config) \n",
    "print(trainer.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): EmbeddingEncoder(\n",
       "    (emb): Embedding(33672, 300)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=1200, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    params.vocab = trainer.vocab\n",
    "    params.encoder = trainer.model.encoder    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['this', 'is', 'an', 'apple', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 220,    6,   20, 1507,    3]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenlist = torch.tensor([[trainer.vocab.stoi[word] for word in sentence]])\n",
    "tokenlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'an', 'apple', '.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[trainer.vocab.itos[token] for token in tokenlist[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.encoder((tokenlist, [len(tokenlist)])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(params, batch):\n",
    "    # if a sentence is empty dot is set to be the only token\n",
    "    # you can change it into NULL dependening in your model\n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "\n",
    "    for sent in batch:\n",
    "        sentvec = []\n",
    "        # the format of a sentence is a lists of words (tokenized and lowercased)\n",
    "        sent_tokens = torch.tensor([[params.vocab.stoi[word] for word in sent]])\n",
    "        x = (sent_tokens, [len(sent_tokens)])\n",
    "        with torch.no_grad():\n",
    "            sent_vec = params.encoder(x)\n",
    "        embeddings.append(sent_vec.detach().numpy())\n",
    "    # [batch size, embedding dimensionality]\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 2}\n",
    "params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 128,\n",
    "                                 'tenacity': 2, 'epoch_size': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "se = senteval.engine.SE(params_senteval, batcher, prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you define the NLP taks that your embedding model is going to be evaluated\n",
    "# in (https://arxiv.org/abs/1802.05883) we use the following :\n",
    "# SICKRelatedness (Sick-R) needs torch cuda to work (even when using logistic regression), \n",
    "# but STS14 (semantic textual similarity) is a similar type of semantic task\n",
    "transfer_tasks = ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC',\n",
    "                  'MRPC', 'SICKEntailment', 'STS14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# senteval prints the results and returns a dictionary with the scores\n",
    "results = se.eval(transfer_tasks)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exp_name': 'uni_lstm',\n",
       " 'epochs': 20,\n",
       " 'encoder': 'UniLSTM',\n",
       " 'batch_size': 128,\n",
       " 'hidden_dim': 2048,\n",
       " 'num_layers': 1,\n",
       " 'learning_rate': 0.001,\n",
       " 'seed': 42,\n",
       " 'debug': False,\n",
       " 'device': 'cpu',\n",
       " 'num_workers': 4,\n",
       " 'valid_freq': 1000,\n",
       " 'save_freq': 4000,\n",
       " 'test_checkpoint': 'best-model.pt'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configs.uni_lstm import config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:trainer:--------------------------------------------------\n",
      "INFO:trainer:EXPERIMENT: uni_lstm\n",
      "INFO:trainer:--------------------------------------------------\n",
      "INFO:trainer:Setting seed: 42\n",
      "INFO:trainer:Loading data ...\n",
      "INFO:trainer:Using device: cpu\n",
      "INFO:trainer:Loading checkpoint from checkpoints/uni_lstm/best-model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Test]\tAccuracy: 0.812 Total Loss: 0.517\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config) \n",
    "print(trainer.test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (encoder): UniLSTM(\n",
       "    (emb): Embedding(33672, 300)\n",
       "    (lstm): LSTM(300, 2048, batch_first=True)\n",
       "  )\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=8192, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(params, samples):\n",
    "    params.vocab = trainer.vocab\n",
    "    params.encoder = trainer.model.encoder    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = ['this', 'is', 'an', 'apple', '.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 220,    6,   20, 1507,    3]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenlist = torch.tensor([[trainer.vocab.stoi[word] for word in sentence]])\n",
    "tokenlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'an', 'apple', '.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[trainer.vocab.itos[token] for token in tokenlist[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.encoder((tokenlist, [len(tokenlist)])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher(params, batch):\n",
    "    # if a sentence is empty dot is set to be the only token\n",
    "    # you can change it into NULL dependening in your model\n",
    "    batch = [sent if sent != [] else ['.'] for sent in batch]\n",
    "    embeddings = []\n",
    "\n",
    "    for sent in batch:\n",
    "        sentvec = []\n",
    "        # the format of a sentence is a lists of words (tokenized and lowercased)\n",
    "        sent_tokens = torch.tensor([[params.vocab.stoi[word] for word in sent]])\n",
    "        x = (sent_tokens, [len(sent_tokens)])\n",
    "        with torch.no_grad():\n",
    "            sent_vec = params.encoder(x)\n",
    "        embeddings.append(sent_vec.detach().numpy())\n",
    "    # [batch size, embedding dimensionality]\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'task_path': PATH_TO_DATA, 'usepytorch': True, 'kfold': 2}\n",
    "params['classifier'] = {'nhid': 0, 'optim': 'adam', 'batch_size': 128,\n",
    "                                 'tenacity': 2, 'epoch_size': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(message)s', level=logging.DEBUG)\n",
    "se = senteval.engine.SE(params_senteval, batcher, prepare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you define the NLP taks that your embedding model is going to be evaluated\n",
    "# in (https://arxiv.org/abs/1802.05883) we use the following :\n",
    "# SICKRelatedness (Sick-R) needs torch cuda to work (even when using logistic regression), \n",
    "# but STS14 (semantic textual similarity) is a similar type of semantic task\n",
    "transfer_tasks = ['MR', 'CR', 'MPQA', 'SUBJ', 'SST2', 'TREC',\n",
    "                  'MRPC', 'SICKEntailment', 'STS14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# senteval prints the results and returns a dictionary with the scores\n",
    "results = se.eval(transfer_tasks)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:prod] *",
   "language": "python",
   "name": "conda-env-prod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
